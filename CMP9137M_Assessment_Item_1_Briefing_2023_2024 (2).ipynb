{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlGnt2es6bGU",
        "outputId": "967c8394-7eff-4524-a476-cf0d3ed8d324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries (uncomment if you need to install them)\n",
        "# !pip install tensorflow pandas matplotlib\n",
        "\n",
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Check TensorFlow version to ensure it's installed correctly\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/awsaf49/flickr-dataset/releases/download/v1.0/flickr8k.zip\"\n",
        "!unzip -q flickr8k.zip -d ./flickr8k\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbqlrlhw62xt",
        "outputId": "14ac8ea1-20fe-426b-a9e6-691c7f868aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-12 12:47:14--  https://github.com/awsaf49/flickr-dataset/releases/download/v1.0/flickr8k.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/753516996/d7c62b13-1e50-40ea-8fae-f34a44b1695f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240412%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240412T124715Z&X-Amz-Expires=300&X-Amz-Signature=f0b450a735b7ff734cae42883120d2bed1c747a1feaa949f4c81ac7d8d0a1eb6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=753516996&response-content-disposition=attachment%3B%20filename%3Dflickr8k.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-12 12:47:15--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/753516996/d7c62b13-1e50-40ea-8fae-f34a44b1695f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240412%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240412T124715Z&X-Amz-Expires=300&X-Amz-Signature=f0b450a735b7ff734cae42883120d2bed1c747a1feaa949f4c81ac7d8d0a1eb6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=753516996&response-content-disposition=attachment%3B%20filename%3Dflickr8k.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1112971163 (1.0G) [application/octet-stream]\n",
            "Saving to: ‘flickr8k.zip.1’\n",
            "\n",
            "flickr8k.zip.1      100%[===================>]   1.04G   111MB/s    in 11s     \n",
            "\n",
            "2024-04-12 12:47:26 (101 MB/s) - ‘flickr8k.zip.1’ saved [1112971163/1112971163]\n",
            "\n",
            "replace ./flickr8k/Images/1000268201_693b08cb0e.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the captions\n",
        "captions_df = pd.read_csv('./flickr8k/captions.txt')\n",
        "\n",
        "# Display the first few rows to understand the structure\n",
        "print(captions_df.head())\n",
        "\n",
        "# List the image paths\n",
        "image_dir = './flickr8k/Images/'\n",
        "image_paths = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir) if filename.endswith('.jpg')]\n",
        "\n",
        "# Display the first few image paths to ensure they're loaded correctly\n",
        "print(image_paths[:5])\n"
      ],
      "metadata": {
        "id": "ZTo6habtOPxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Initialize a list to hold the no-match pairs\n",
        "no_match_pairs = []\n",
        "\n",
        "# Iterate over each image\n",
        "for image_path in image_paths:\n",
        "    # Randomly select a caption that is not associated with the current image\n",
        "    potential_no_matches = captions_df[~captions_df['image'].str.contains(os.path.basename(image_path))]\n",
        "    random_caption = potential_no_matches.sample(1).iloc[0]['caption']\n",
        "\n",
        "    # Append the no-match pair\n",
        "    no_match_pairs.append({'image': image_path, 'caption': random_caption, 'match': 0})\n",
        "\n",
        "# Convert the no-match pairs to a DataFrame\n",
        "no_match_df = pd.DataFrame(no_match_pairs)\n",
        "\n",
        "# Display the first few rows of the no-match pairs DataFrame\n",
        "print(no_match_df.head())\n"
      ],
      "metadata": {
        "id": "XeE0qjZOOP0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a 'match' column to captions_df, setting all to 1 to indicate these are match pairs\n",
        "captions_df['match'] = 1\n",
        "\n",
        "# Combine the match and no-match pairs into a single DataFrame\n",
        "combined_df = pd.concat([captions_df, no_match_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the combined DataFrame to ensure a mix of match and no-match pairs\n",
        "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Display the first few rows of the combined DataFrame\n",
        "print(combined_df.head())\n"
      ],
      "metadata": {
        "id": "KYNFNymnOP2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a few rows where the 'match' column is 0 to confirm the presence of no-match pairs\n",
        "print(combined_df[combined_df['match'] == 0].head())\n"
      ],
      "metadata": {
        "id": "jrFPxlAaOP4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the combined data into training+validation and test sets (85% training+validation, 15% testing)\n",
        "train_val_df, test_df = train_test_split(combined_df, test_size=0.15, random_state=42)\n",
        "\n",
        "# Splitting the training+validation data further into training and validation sets (82.35% training, 17.65% validation which is about 70% of the original data for training and 15% for validation)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.1765, random_state=42)  # 0.1765 is approximately 15/85\n",
        "\n",
        "# Display the size of each set\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Testing set size: {len(test_df)}\")\n"
      ],
      "metadata": {
        "id": "IgV1gv-AOP6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./flickr8k/Images/\n"
      ],
      "metadata": {
        "id": "e_f2aemxTlSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['image'].head())\n"
      ],
      "metadata": {
        "id": "rI2Yuv-sToDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepend the image directory path to each image filename in the DataFrame\n",
        "train_df['image'] = image_dir + train_df['image']\n"
      ],
      "metadata": {
        "id": "_zOq8fq2UPLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct the image paths in the DataFrame\n",
        "train_df['image'] = train_df['image'].apply(lambda x: x.replace(image_dir, '') if x.startswith(image_dir) else x)\n",
        "train_df['image'] = image_dir + train_df['image']\n",
        "\n",
        "# Verify the correction by displaying the first few image paths\n",
        "print(train_df['image'].head())\n"
      ],
      "metadata": {
        "id": "oQy3RY4aUk6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(224, 224))  # Resize image\n",
        "    img_array = img_to_array(img)  # Convert to array\n",
        "    img_array = img_array / 255.0  # Normalize to [0, 1] range\n",
        "    return img_array\n",
        "\n",
        "# Apply the preprocessing to each image in the training set\n",
        "# Creating a smaller subset for training to avoid memory issues\n",
        "small_train_df = train_df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Applying the preprocessing to each image in the smaller training set\n",
        "small_train_images = np.array([preprocess_image(path) for path in small_train_df['image']])\n",
        "\n"
      ],
      "metadata": {
        "id": "roV1MBSeOP9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eUEtdXiZOP_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoGV5j0QOQCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PqJaSUdOOQEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOkiEuj2OQGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I1xC2QkSOQI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOqNUqkzOQLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uCyYFA34OQNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FR8td8gcOQP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1FfQKxOjOQSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "URs2uNudOQVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yKCgTjTDMj2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}